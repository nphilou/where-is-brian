{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/philippe/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/philippe/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package wordnet to /home/philippe/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import scipy\n",
    "from sklearn import svm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english = pandas.read_csv(\"train_cap2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27310,)\n(27310, 6)\n"
     ]
    }
   ],
   "source": [
    "target = english['level1']\n",
    "target.head()\n",
    "print(target.shape)\n",
    "\n",
    "# data\n",
    "data = english.loc[:, \"fulltext\":\"punct\"]\n",
    "print(data.shape)\n",
    "\n",
    "# words_data : \n",
    "text = english.loc[:, \"fulltext\"]\n",
    "words_data = text.map(lambda t: word_tokenize(t))\n",
    "\n",
    "\n",
    "# print(data.loc[3][\"fulltext\"][0])\n",
    "# sentence = data[:3][\"fulltext\"][0]\n",
    "# sentence = data.as_matrix()[27309, 0]\n",
    "# print(sentence)\n",
    "# words = word_tokenize(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sixteen',\n 'headphones',\n '.',\n 'also',\n 'there',\n 'are',\n 'thirty',\n 'pens',\n 'and',\n 'fifteen',\n 'pencils',\n '.',\n 'also',\n 'there',\n 'are',\n 'twelve',\n 'desks',\n ',',\n 'fourteen',\n 'chairs',\n 'and',\n 'one',\n 'table',\n '.',\n 'bye']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_data[27304]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'my', 'name', \"'s\", 'Jean-Marc', '.', 'I', \"'m\", 'a', 'management', 'controller', '.', 'I', 'work', 'in', 'an', 'office', '.', 'My', 'favorite', 'day', 'in', 'Sunday', '.', 'I', 'get', 'up', 'at', 'eight', \"o'clock\", 'in', 'the', 'morning', 'on', 'Sunday', ',', 'have', 'a', 'shower', ',', 'brush', 'my', 'teeth', 'and', 'go', 'running', '.', 'I', 'have', 'lunch', 'at', 'twelve', \"o'clock\", 'in', 'the', 'afternoon', '.', 'I', 'go', 'swimming', 'in', 'the', 'evening', ',', 'I', 'meet', 'friends', '.', 'We', 'eat', 'in', 'a', 'restaurant', 'then', 'go', 'to', 'the', 'movies', 'and', 'watch', 'a', 'movie', '.', 'I', 'go', 'to', 'bed', 'at', 'eleven', \"o'clock\", '.']\n52\n91\n0.5714285714285714\n0.6238532110091743\n0.6938775510204082\n"
     ]
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(words_data[27304])\n",
    "\n",
    "print(words_data[27305])\n",
    "\n",
    "print(len(set(words_data[27305])))\n",
    "\n",
    "print(len(words_data[27305]))\n",
    "print(len(set(words_data[27305])) / len(words_data[27305]))\n",
    "print(len(set(words_data[3000])) / len(words_data[3000]))\n",
    "print(len(set(words_data[2])) / len(words_data[2]))\n",
    "\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)\n",
    "\n",
    "\n",
    "ld = words_data.map(lambda t: lexical_diversity(t))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C2</th>\n",
       "      <td>[The, Eiffel, Tower, is, a, symbol, of, domina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>[Since, our, meeting, I, 've, heard, your, req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>[At, the, beginning, of, the, metting, the, CE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>[Hello, my, friend, ,, I, would, like, to, tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>[Dear, friends, ,, excuse, me, but, I, could, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>[Hello, My, name, 's, David, ., I, 'm, from, F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C2</th>\n",
       "      <td>[The, Eiffel, Tower, is, a, symbol, of, domina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>[Since, our, meeting, I, 've, heard, your, req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>[At, the, beginning, of, the, metting, the, CE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>[Hello, my, friend, ,, I, would, like, to, tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>[Dear, friends, ,, excuse, me, but, I, could, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>[Hello, My, name, 's, David, ., I, 'm, from, F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "\n",
    "#words_lem = map(lambda s: set(map(wordnet_lemmatizer.lemmatize, s)), words_data)\n",
    "#words_target = list(zip(target, words_lem))\n",
    "#df = pandas.DataFrame.from_records(words_target, columns=['level', 'words'])\n",
    "\n",
    "#print(df)\n",
    "#df['words'].groupby(df['level'])\n",
    "\n",
    "pdf = pandas.DataFrame({'level': target, 'words': words_data})\n",
    "grouped = pdf.groupby(['level'], sort=False).sum()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C2</th>\n",
       "      <td>{appeared, industry, mortgage, private, Hollyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>{mix, industry, typically, requirement, date, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>{attacked, mix, interests.Then, industry, seaf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>{Artists, attacked, mix, Keo, actuelly, indust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>{attacked, mix, Humez, *Pascal, requirement, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>{-across, attacked, LYON, Reyrieux, mix, lieve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C2</th>\n",
       "      <td>{appeared, industry, mortgage, private, Hollyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>{mix, industry, typically, requirement, date, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>{attacked, mix, interests.Then, industry, seaf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>{Artists, attacked, mix, Keo, actuelly, indust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>{attacked, mix, Humez, *Pascal, requirement, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>{-across, attacked, LYON, Reyrieux, mix, lieve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "grouped_in_set = grouped.applymap(lambda l: set(map(lemmatizer.lemmatize, l)))\n",
    "grouped_in_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff_words_count = grouped_in_set.applymap(lambda s: len({w for w in s if w[0].islower()}))\n",
    "diff_words = grouped_in_set.applymap(lambda s: {w for w in s if w[0].islower()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_lem = words_data.apply(lambda l: set(map(lemmatizer.lemmatize, l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_words_count[\"words\"][\"C2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8389830508474576\n0.7372881355932204\n0.7288135593220338\n0.7457627118644068\n0.7457627118644068\n0.652542372881356\n0.5657894736842105\n0.6842105263157895\n0.7368421052631579\n0.7236842105263158\n0.7105263157894737\n0.8421052631578947\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-ac3f8f6439fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdist_A1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_lem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mdiff_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist_C2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdist_C1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdist_B2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdist_B1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdist_A2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdist_A1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/philippe/Code/where-is-brian/venv/lib/python3.5/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m   1260\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philippe/Code/where-is-brian/venv/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_combine_series\u001b[0;34m(self, other, func, fill_value, axis, level, try_cast)\u001b[0m\n\u001b[1;32m   3942\u001b[0m         return self._combine_series_infer(other, func, level=level,\n\u001b[1;32m   3943\u001b[0m                                           \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3944\u001b[0;31m                                           try_cast=try_cast)\n\u001b[0m\u001b[1;32m   3945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3946\u001b[0m     def _combine_series_infer(self, other, func, level=None,\n",
      "\u001b[0;32m/home/philippe/Code/where-is-brian/venv/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_combine_series_infer\u001b[0;34m(self, other, func, level, fill_value, try_cast)\u001b[0m\n\u001b[1;32m   3956\u001b[0m         return self._combine_match_columns(other, func, level=level,\n\u001b[1;32m   3957\u001b[0m                                            \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3958\u001b[0;31m                                            try_cast=try_cast)\n\u001b[0m\u001b[1;32m   3959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3960\u001b[0m     def _combine_match_index(self, other, func, level=None,\n",
      "\u001b[0;32m/home/philippe/Code/where-is-brian/venv/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_combine_match_columns\u001b[0;34m(self, other, func, level, fill_value, try_cast)\u001b[0m\n\u001b[1;32m   3979\u001b[0m         new_data = left._data.eval(func=func, other=right,\n\u001b[1;32m   3980\u001b[0m                                    \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3981\u001b[0;31m                                    try_cast=try_cast)\n\u001b[0m\u001b[1;32m   3982\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philippe/Code/where-is-brian/venv/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3437\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philippe/Code/where-is-brian/venv/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3285\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'where'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philippe/Code/where-is-brian/venv/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3829\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3830\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3831\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3832\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philippe/Code/where-is-brian/venv/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   4851\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4852\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[0;32m-> 4853\u001b[0;31m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[1;32m   4854\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4855\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philippe/Code/where-is-brian/venv/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[1;32m   4871\u001b[0m         \u001b[0;31m# combination of those slices is a slice, too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4872\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4873\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4875\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philippe/Code/where-is-brian/venv/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_vstack\u001b[0;34m(to_stack, dtype)\u001b[0m\n\u001b[1;32m   4917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4918\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4919\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philippe/Code/where-is-brian/venv/lib/python3.5/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print(len(words_lem[1] & diff_words[\"words\"][\"C2\"])/len(words_lem[1]))\n",
    "print(len(words_lem[1] & diff_words[\"words\"][\"C1\"])/len(words_lem[1]))\n",
    "print(len(words_lem[1] & diff_words[\"words\"][\"B2\"])/len(words_lem[1]))\n",
    "print(len(words_lem[1] & diff_words[\"words\"][\"B1\"])/len(words_lem[1]))\n",
    "print(len(words_lem[1] & diff_words[\"words\"][\"A2\"])/len(words_lem[1]))\n",
    "print(len(words_lem[1] & diff_words[\"words\"][\"A1\"])/len(words_lem[1]))\n",
    "\n",
    "print(len(words_lem[27306] & diff_words[\"words\"][\"C2\"])/len(words_lem[27306]))\n",
    "print(len(words_lem[27306] & diff_words[\"words\"][\"C1\"])/len(words_lem[27306]))\n",
    "print(len(words_lem[27306] & diff_words[\"words\"][\"B2\"])/len(words_lem[27306]))\n",
    "print(len(words_lem[27306] & diff_words[\"words\"][\"B1\"])/len(words_lem[27306]))\n",
    "print(len(words_lem[27306] & diff_words[\"words\"][\"A2\"])/len(words_lem[27306]))\n",
    "print(len(words_lem[27306] & diff_words[\"words\"][\"A1\"])/len(words_lem[27306]))\n",
    "\n",
    "dist_C2 = pandas.DataFrame(words_lem.map(lambda t: len(t & diff_words[\"words\"][\"C2\"])/len(t)))\n",
    "dist_C1 = pandas.DataFrame(words_lem.map(lambda t: len(t & diff_words[\"words\"][\"C1\"])/len(t)))\n",
    "dist_B2 = pandas.DataFrame(words_lem.map(lambda t: len(t & diff_words[\"words\"][\"B2\"])/len(t)))\n",
    "dist_B1 = pandas.DataFrame(words_lem.map(lambda t: len(t & diff_words[\"words\"][\"B1\"])/len(t)))\n",
    "dist_A2 = pandas.DataFrame(words_lem.map(lambda t: len(t & diff_words[\"words\"][\"A2\"])/len(t)))\n",
    "dist_A1 = pandas.DataFrame(words_lem.map(lambda t: len(t & diff_words[\"words\"][\"A1\"])/len(t)))\n",
    "\n",
    "dist = dist_C2 + dist_C1 + dist_B2 + dist_B1 + dist_A2 + dist_A1 + target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "y = english.groupby('level1').sentences.count()\n",
    "plt.bar(y.keys(), y.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n     verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = svm.SVC(gamma=0.001, C=100.)\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(random_state=0) \n",
    "data_cleaned = data.T.dropna().T\n",
    "\n",
    "clf.fit(data_cleaned, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentences  words  letters.all  syllables  punct\n0         16    233         1116        363     32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['B1'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.head()\n",
    "\n",
    "print(data_cleaned[:1])\n",
    "clf.predict(data_cleaned[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 48 ms, total: 1min 29s\nWall time: 1min 50s\n[0.5610247  0.56232839 0.57817649 0.5521978  0.54542125]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "%time listerr = cross_val_score(clf, data_cleaned, target, cv=5)\n",
    "print listerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data_standard = StandardScaler().fit_transform(data_cleaned)\n",
    "corr = np.corrcoef(data_standard.T)\n",
    "corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.66837766, 0.64175596, 0.64342692, 0.73276522],\n       [0.66837766, 1.        , 0.98341281, 0.98538917, 0.71997432],\n       [0.64175596, 0.98341281, 1.        , 0.99595057, 0.70399435],\n       [0.64342692, 0.98538917, 0.99595057, 1.        , 0.71004385],\n       [0.73276522, 0.71997432, 0.70399435, 0.71004385, 1.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sea\n",
    "sea.heatmap(corr)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
